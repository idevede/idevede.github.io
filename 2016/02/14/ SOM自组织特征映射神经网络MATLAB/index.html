<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>SOM自组织特征映射神经网络-MATLAB | Dove&#39;s bolg</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="本文在CSDN的地址：点这里一篇转载的不错的介绍ＳＯＭ的文章">
<meta name="keywords" content="算法,可视化,MATLAB">
<meta property="og:type" content="article">
<meta property="og:title" content="SOM自组织特征映射神经网络-MATLAB">
<meta property="og:url" content="https://idevede.github.io/2016/02/14/ SOM自组织特征映射神经网络MATLAB/index.html">
<meta property="og:site_name" content="Dove&#39;s bolg">
<meta property="og:description" content="本文在CSDN的地址：点这里一篇转载的不错的介绍ＳＯＭ的文章">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://s9.sinaimg.cn/orignal/7671b3eb4af4c74430f38&690">
<meta property="og:image" content="http://s7.sinaimg.cn/orignal/7671b3eb4af4d986c8f96&690">
<meta property="og:image" content="http://s14.sinaimg.cn/orignal/7671b3eb4af4dce12150d&690">
<meta property="og:updated_time" content="2018-07-07T04:11:20.929Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SOM自组织特征映射神经网络-MATLAB">
<meta name="twitter:description" content="本文在CSDN的地址：点这里一篇转载的不错的介绍ＳＯＭ的文章">
<meta name="twitter:image" content="http://s9.sinaimg.cn/orignal/7671b3eb4af4c74430f38&690">
  
    <link rel="alternate" href="/atom.xml" title="Dove&#39;s bolg" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Dove&#39;s bolg</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://idevede.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post- SOM自组织特征映射神经网络MATLAB" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/14/ SOM自组织特征映射神经网络MATLAB/" class="article-date">
  <time datetime="2016-02-14T15:09:26.000Z" itemprop="datePublished">2016-02-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      SOM自组织特征映射神经网络-MATLAB
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文在CSDN的地址：<a href="https://blog.csdn.net/idevede/article/details/52396823" target="_blank" rel="noopener">点这里</a><br>一篇转载的不错的介绍ＳＯＭ的文章</p>
<a id="more"></a>
<p>n clustering problems, you want a neural network to group data by similarity.</p>
<p>A self-organizing map (newsom) consists of a competitive layer which can classify a dataset of vectors with any number of dimensions into as many classes as the layer has neurons. The neurons are arranged in a 2D topology, which allows the layer to form a representation of the distribution and a two-dimensional approximation of the topology of the dataset.</p>
<p>The network is trained with the SOM batch algorithm (trainubwb, learnsomb).</p>
<p><img src="http://s9.sinaimg.cn/orignal/7671b3eb4af4c74430f38&amp;690" alt="SOM batch algorithm"></p>
<h2 id="神经网络创建函数"><a href="#神经网络创建函数" class="headerlink" title="神经网络创建函数"></a>神经网络创建函数</h2><p>（一）newsom函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">net=newsom(PR,[D1,D2,^],TFCN,DFCN,OLR,OSTEPS,TLR,TND)</span><br><span class="line"></span><br><span class="line">PR:R个输入元素的最大值和最小值的设定值，R*2维矩阵</span><br><span class="line"></span><br><span class="line">Di：第I层的维数，默认为[5 8]</span><br><span class="line"></span><br><span class="line">TFCN：拓扑函数，默认为hextop</span><br><span class="line"></span><br><span class="line">DFCN:距离函数，默认为linkdist</span><br><span class="line"></span><br><span class="line">OLR：分类阶段学习速率，默认为0.9</span><br><span class="line"></span><br><span class="line">OSTEPS：分类阶段的步长，默认为1000</span><br><span class="line"></span><br><span class="line">TLR：调谐阶段的学习速率，默认为0.02</span><br><span class="line"></span><br><span class="line">TNS:调谐阶段的领域距离，默认为1.</span><br></pre></td></tr></table></figure></p>
<p>输入net=newsom([0 1;0 1],[3 5])时的拓扑结构<br><img src="http://s7.sinaimg.cn/orignal/7671b3eb4af4d986c8f96&amp;690" alt="BST算法流程"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">eg.</span><br><span class="line">&gt;&gt; P=[rand(1,400)*2;rand(1,400)];</span><br><span class="line"></span><br><span class="line">&gt;&gt; plot(P(1,:),P(2,:),&apos;.&apos;,&apos;markersize&apos;,20)</span><br><span class="line">&gt;&gt; net=newsom([0 1;0 1],[3 5]);</span><br><span class="line">&gt;&gt; net=train(net,P);</span><br><span class="line">&gt;&gt; hold on</span><br><span class="line">&gt;&gt; plotsom(net.iw&#123;1,1&#125;,net.layers&#123;1&#125;.distances)</span><br><span class="line">&gt;&gt; hold off</span><br></pre></td></tr></table></figure></p>
<p><img src="http://s14.sinaimg.cn/orignal/7671b3eb4af4dce12150d&amp;690" alt="BST算法流程"></p>
<p>（二）newc函数</p>
<p>功能：该函数用于创建一个竞争层<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">net=newc</span><br><span class="line"></span><br><span class="line">net=newc(PR,S,KLR,CLR)</span><br><span class="line"></span><br><span class="line">S:神经元的数目</span><br><span class="line"></span><br><span class="line">KLR：Kohonen学习速度，默认为0.01</span><br><span class="line"></span><br><span class="line">CLR：Conscience学习速度，默认为0.001</span><br><span class="line"></span><br><span class="line">net:函数返回值，一个新的竞争层。</span><br></pre></td></tr></table></figure></p>
<p>（三）newlvq函数</p>
<p>功能：该函数用于创建一个学习向量量化的LVQ网络</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">net=newlvp</span><br><span class="line"></span><br><span class="line">net=newlvp(PR,S1,PC,LR,LF)</span><br><span class="line"></span><br><span class="line">S1:竞争层神经元的数目</span><br><span class="line"></span><br><span class="line">PC：分类的百分比</span><br><span class="line"></span><br><span class="line">LR：学习速率，默认为0.01</span><br><span class="line"></span><br><span class="line">LF:学习函数，默认为learnlvl</span><br></pre></td></tr></table></figure>
<p>例子看<a href="http://blog.sina.com.cn/s/blog_7671b3eb0100y4t3.html" target="_blank" rel="noopener">http://blog.sina.com.cn/s/blog_7671b3eb0100y4t3.html</a></p>
<h2 id="传递函数"><a href="#传递函数" class="headerlink" title="传递函数"></a>传递函数</h2><p>（一）compet函数</p>
<p>功能：该函数为传递函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">A=compet(N)</span><br><span class="line"></span><br><span class="line">info=compet(code)</span><br><span class="line"></span><br><span class="line">N：输入（列）向量的S*Q维矩阵</span><br><span class="line"></span><br><span class="line">A：函数返回值，输出向量矩阵，每一列向量只有一个1，位于输入向量最大的位置</span><br></pre></td></tr></table></figure></p>
<p>info=compet(code)：根据code值的不同返回有关函数的不同信息，包括derice-导数名称；name-函数名称；output-输出范围；active-动态输入范围。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; n1=[5;3;6;8];</span><br><span class="line">&gt;&gt; a1=compet(n1)</span><br><span class="line"></span><br><span class="line">a1 =</span><br><span class="line"></span><br><span class="line">   (4,1)        1</span><br></pre></td></tr></table></figure></p>
<p>（二）softmax函数</p>
<p>功能：该函数为软最大传递函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A=softmax(N)</span><br><span class="line"></span><br><span class="line">info=softmax(code)</span><br></pre></td></tr></table></figure></p>
<p>与compet不同的是，参数A为函数返回向量，个元素在区间[0，1]，且向量结构与N一致。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; n1=[5;3;6;8];</span><br><span class="line">&gt;&gt; a2=softmax(n1)</span><br><span class="line"></span><br><span class="line">a2 =</span><br><span class="line"></span><br><span class="line">    0.0418</span><br><span class="line">    0.0057</span><br><span class="line">    0.1135</span><br><span class="line">    0.8390</span><br></pre></td></tr></table></figure></p>
<h2 id="距离函数"><a href="#距离函数" class="headerlink" title="距离函数"></a>距离函数</h2><p>（一）boxdist函数</p>
<p>功能：该函数为Box距离函数，在给定神经网络某层的神经元的位置后，可利用该函数计算神经元之间的位置，该函数通常用于结构函数的gridtop的神经网络层。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">d=boxdist(pos)</span><br><span class="line"></span><br><span class="line">ps:神经元位置的N*S维矩阵</span><br><span class="line"></span><br><span class="line">d：函数返回值，神经元距离的S*S维矩阵。</span><br></pre></td></tr></table></figure></p>
<p>函数的运算原理为d(i,j)=max||pi-pj||。其中，d(i,j)表示距离矩阵中的元素，pi表示位置矩阵的第i列向量。</p>
<p>（二）dist函数</p>
<p>功能：该函数的欧式距离权函数，通过对输入进行加权得到加权后的输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Z=dist(W,P);</span><br><span class="line"></span><br><span class="line">df=dist(&apos;deriv&apos;)</span><br><span class="line"></span><br><span class="line">D=dist(pos)</span><br><span class="line"></span><br><span class="line">W:S*R维的权值矩阵</span><br><span class="line"></span><br><span class="line">P:Q组输入（列）向量的R*Q维矩阵</span><br><span class="line"></span><br><span class="line">Z:S*Q维的距离矩阵</span><br><span class="line"></span><br><span class="line">pos:神经元位置的N*S维矩阵</span><br><span class="line"></span><br><span class="line">D:S*S维的距离矩阵</span><br><span class="line"></span><br><span class="line">df=dist(&apos;deriv&apos;)：返回值为空，因为该函数不存在导函数。</span><br></pre></td></tr></table></figure></p>
<p>函数运算规则为D=sqrt(sum((x-y)2))，其中x和y分别为列向量。</p>
<p>（三）linkdist函数</p>
<p>功能：该函数为连接距离函数，在给定神经元的位置后，该函数可用于计算神经元之间的距离<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d=linkdist(pos)</span><br></pre></td></tr></table></figure></p>
<p>（四）mandist函数</p>
<p>功能：该函数为Manhattan距离权函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Z=mandist(W,P)</span><br><span class="line"></span><br><span class="line">df=mandist(&apos;deriv&apos;)</span><br><span class="line"></span><br><span class="line">D=mandist(pos)</span><br></pre></td></tr></table></figure></p>
<h2 id="学习函数"><a href="#学习函数" class="headerlink" title="学习函数"></a>学习函数</h2><p>（一）learnk函数</p>
<p>功能：该函数为kohonen权值学习函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[dw,LS]=learnk(W,P,Z,N,A,T,E,gW,gA,D,LP,LS)</span><br><span class="line"></span><br><span class="line">info=learnk(code)</span><br><span class="line"></span><br><span class="line">W:权值矩阵</span><br><span class="line"></span><br><span class="line">P:输入向量矩阵</span><br><span class="line"></span><br><span class="line">Z:权值输入向量矩阵</span><br><span class="line"></span><br><span class="line">N:网格输入向量矩阵</span><br><span class="line"></span><br><span class="line">A:输出向量矩阵</span><br><span class="line"></span><br><span class="line">T:目标向量矩阵</span><br><span class="line"></span><br><span class="line">E:误差向量矩阵</span><br><span class="line"></span><br><span class="line">gW:性能梯度矩阵</span><br><span class="line"></span><br><span class="line">D:神经元距离矩阵</span><br><span class="line"></span><br><span class="line">LP:学习参数，若无则为空</span><br><span class="line"></span><br><span class="line">LS:学习状态，初始化为空</span><br><span class="line"></span><br><span class="line">dW：权值（阈值）变化矩阵</span><br><span class="line"></span><br><span class="line">LS:新的学习状态</span><br><span class="line"></span><br><span class="line">info=learnk(code)……</span><br></pre></td></tr></table></figure></p>
<p>(二)learnsom函数</p>
<p>功能：该函数为自组织映射权值学习函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[dW,LS]=learnsom(W,P,Z,N,A,T,E,gW,gA,D,LP,LS)</span><br><span class="line"></span><br><span class="line">info=learnsom(code)</span><br><span class="line"></span><br><span class="line">几个需要设置的学习参数</span><br><span class="line"></span><br><span class="line">LP.order_lr分类阶段学习速率，默认0.9</span><br><span class="line"></span><br><span class="line">LP.order_steps学习阶段补偿，默认1000</span><br><span class="line"></span><br><span class="line">LP.tune_lr调谐阶段领域距离，默认0.02</span><br><span class="line"></span><br><span class="line">LP.tune_nd调谐阶段学习速率，默认1</span><br></pre></td></tr></table></figure></p>
<p>（三）learnis函数</p>
<p>功能：该函数为instar权值学习函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[dW,LS]=learnis(W,P,Z,N,A,T,E,gW,gA,D,LP,LS)</span><br><span class="line"></span><br><span class="line">info=learnis(code)</span><br></pre></td></tr></table></figure></p>
<p>（四）learnos函数</p>
<h2 id="初始化函数（midpoint）"><a href="#初始化函数（midpoint）" class="headerlink" title="初始化函数（midpoint）"></a>初始化函数（midpoint）</h2><p>功能：该函数为i中心点权值初始化函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">W=midpoint(S,PR)</span><br><span class="line"></span><br><span class="line">S:神经元的数目；</span><br><span class="line"></span><br><span class="line">PR:每组输入向量的最大值和最小值组成的R*2维矩阵，规定了输入区间为[Pmin，Pmax]</span><br><span class="line"></span><br><span class="line">W:函数返回值，S*R维的矩阵，每个元素对应设定为（Pmin+Pmax）/2</span><br></pre></td></tr></table></figure></p>
<h2 id="权值函数（negdist）"><a href="#权值函数（negdist）" class="headerlink" title="权值函数（negdist）"></a>权值函数（negdist）</h2><p>功能：该函数为负距离权值函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Z=negdist(W,P)</span><br></pre></td></tr></table></figure></p>
<h2 id="显示函数（plotsom）"><a href="#显示函数（plotsom）" class="headerlink" title="显示函数（plotsom）"></a>显示函数（plotsom）</h2><p>功能：该函数用于绘制自组织特征映射<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">plotsom(pos)</span><br><span class="line"></span><br><span class="line">plotsom(W,D,ND)</span><br><span class="line"></span><br><span class="line">pos:神经元位置向量</span><br><span class="line"></span><br><span class="line">W:权值矩阵</span><br><span class="line"></span><br><span class="line">D:距离矩阵</span><br><span class="line"></span><br><span class="line">ND：领域矩阵，默认为1</span><br><span class="line"></span><br><span class="line">plotsom（pos）：利用红点绘制神经元的位置，将欧氏距离小于等于1的神经元连接起来</span><br><span class="line"></span><br><span class="line">plotsom(W,D,ND)：将欧氏距离小于等于1的神经元的权值向量连接起来</span><br></pre></td></tr></table></figure></p>
<h2 id="结构函数（hextop）"><a href="#结构函数（hextop）" class="headerlink" title="结构函数（hextop）"></a>结构函数（hextop）</h2><p>六角层结构函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">pos=hextop(dim1,dim2,^dimN)</span><br><span class="line"></span><br><span class="line">eg.</span><br><span class="line"></span><br><span class="line">pos=hextop(8,5);</span><br><span class="line">plotsom(pos)</span><br><span class="line"></span><br><span class="line">W=rands(40,2);plotsom(W,dist(pos))</span><br></pre></td></tr></table></figure></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://idevede.github.io/2016/02/14/ SOM自组织特征映射神经网络MATLAB/" data-id="cjjaw6pkm00002gqt8xilmikn" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MATLAB/">MATLAB</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/可视化/">可视化</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/算法/">算法</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/03/14/[计算机网络]各种时延的计算/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          计算机网络:各种时延的计算
        
      </div>
    </a>
  
  
    <a href="/2016/02/14/我写数据结构排序部分的部分心得/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">我写数据结构排序部分的部分心得</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/学习心得/">学习心得</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/我的心得/">我的心得</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/操作系统/">操作系统</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据库/">数据库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据结构/">数据结构</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/数据结构/学习心得/">学习心得</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/硬件编程/">硬件编程</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/硬件编程语言/">硬件编程语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法设计/">算法设计</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/C语言/">C语言</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/FPGA/">FPGA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GUI/">GUI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/">Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MATLAB/">MATLAB</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MySQL/">MySQL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nachos/">Nachos</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/caffe/">caffe</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/">git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/中断/">中断</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/可视化/">可视化</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/哈弗曼树/">哈弗曼树</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/图论/">图论</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/地图/">地图</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/安卓/">安卓</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/嵌入式/">嵌入式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/我的心得/">我的心得</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/操作系统/">操作系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据库/">数据库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据挖掘/">数据挖掘</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据结构/">数据结构</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据结构，算法设计/">数据结构，算法设计</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/文件操作/">文件操作</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/时延/">时延</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/最小生成树/">最小生成树</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/硬件编程/">硬件编程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/神经网络/">神经网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/移动开发/">移动开发</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法/">算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法设计/">算法设计</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/线程/">线程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/编码/">编码</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/编程/">编程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网络编程/">网络编程</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/蚁群算法，算法设计/">蚁群算法，算法设计</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/计算机网络/">计算机网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/设计模式/">设计模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/译码/">译码</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/软件安装/">软件安装</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/随笔/">随笔</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/面向对象/">面向对象</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/C语言/" style="font-size: 11.43px;">C语言</a> <a href="/tags/FPGA/" style="font-size: 10px;">FPGA</a> <a href="/tags/GUI/" style="font-size: 10px;">GUI</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/MATLAB/" style="font-size: 10px;">MATLAB</a> <a href="/tags/MySQL/" style="font-size: 10px;">MySQL</a> <a href="/tags/Nachos/" style="font-size: 14.29px;">Nachos</a> <a href="/tags/caffe/" style="font-size: 10px;">caffe</a> <a href="/tags/git/" style="font-size: 10px;">git</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/中断/" style="font-size: 10px;">中断</a> <a href="/tags/可视化/" style="font-size: 12.86px;">可视化</a> <a href="/tags/哈弗曼树/" style="font-size: 14.29px;">哈弗曼树</a> <a href="/tags/图论/" style="font-size: 12.86px;">图论</a> <a href="/tags/地图/" style="font-size: 10px;">地图</a> <a href="/tags/安卓/" style="font-size: 10px;">安卓</a> <a href="/tags/嵌入式/" style="font-size: 10px;">嵌入式</a> <a href="/tags/我的心得/" style="font-size: 11.43px;">我的心得</a> <a href="/tags/操作系统/" style="font-size: 18.57px;">操作系统</a> <a href="/tags/数据库/" style="font-size: 10px;">数据库</a> <a href="/tags/数据挖掘/" style="font-size: 10px;">数据挖掘</a> <a href="/tags/数据结构/" style="font-size: 20px;">数据结构</a> <a href="/tags/数据结构，算法设计/" style="font-size: 10px;">数据结构，算法设计</a> <a href="/tags/文件操作/" style="font-size: 15.71px;">文件操作</a> <a href="/tags/时延/" style="font-size: 10px;">时延</a> <a href="/tags/最小生成树/" style="font-size: 11.43px;">最小生成树</a> <a href="/tags/机器学习/" style="font-size: 11.43px;">机器学习</a> <a href="/tags/硬件编程/" style="font-size: 10px;">硬件编程</a> <a href="/tags/神经网络/" style="font-size: 10px;">神经网络</a> <a href="/tags/移动开发/" style="font-size: 10px;">移动开发</a> <a href="/tags/算法/" style="font-size: 11.43px;">算法</a> <a href="/tags/算法设计/" style="font-size: 17.14px;">算法设计</a> <a href="/tags/线程/" style="font-size: 14.29px;">线程</a> <a href="/tags/编码/" style="font-size: 20px;">编码</a> <a href="/tags/编程/" style="font-size: 11.43px;">编程</a> <a href="/tags/网络编程/" style="font-size: 10px;">网络编程</a> <a href="/tags/蚁群算法，算法设计/" style="font-size: 10px;">蚁群算法，算法设计</a> <a href="/tags/计算机网络/" style="font-size: 10px;">计算机网络</a> <a href="/tags/设计模式/" style="font-size: 11.43px;">设计模式</a> <a href="/tags/译码/" style="font-size: 14.29px;">译码</a> <a href="/tags/软件安装/" style="font-size: 12.86px;">软件安装</a> <a href="/tags/随笔/" style="font-size: 10px;">随笔</a> <a href="/tags/面向对象/" style="font-size: 11.43px;">面向对象</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">November 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">October 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">May 2015</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/07/07/网上调研：主流网络技术和设备的性能与市场/">(no title)</a>
          </li>
        
          <li>
            <a href="/2018/07/06/Qemu中TCG操作数的定义及注释/">Qemu中TCG操作数的定义及注释</a>
          </li>
        
          <li>
            <a href="/2017/10/15/caffe-源码学习——只看一篇就够了/">caffe-源码学习——只看一篇就够了</a>
          </li>
        
          <li>
            <a href="/2017/08/15/linux C串口常规设置参考/">linux C串口常规设置参考</a>
          </li>
        
          <li>
            <a href="/2017/07/15/P问题NP问题和NPC问题/">什么是P问题、NP问题和NPC问题</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Dove Cao<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>